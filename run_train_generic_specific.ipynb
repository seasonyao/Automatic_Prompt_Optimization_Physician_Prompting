{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["%%capture\n","!pip install openai"],"metadata":{"id":"m2nOCQ5vmd-u"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5HUBqb2TF61j"},"outputs":[],"source":["import pandas as pd\n","import openai"]},{"cell_type":"code","source":["trainA = pd.read_csv('TaskA-TrainingSet.csv')"],"metadata":{"id":"Mh3Ix5XJgCrj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sections = trainA['section_header'].unique().tolist()\n","max_tokens = {}\n","\n","for s in sections:\n","  s_df = trainA[trainA['section_header'] == s]\n","  avg_chars = s_df['section_text'].str.len().mean()\n","  max_tokens[s] = int(round(avg_chars/4))"],"metadata":{"id":"nMjnp_s_WwWp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["abb_to_full = {\n"," 'GENHX': \"History of Present Illness\",\n"," 'ROS': \"Review of Systems\",\n"," 'PASTMEDICALHX': \"Past Medical History\",\n"," 'MEDICATIONS': \"Medications\",\n"," 'CC': \"Chief Complaint\",\n"," 'PASTSURGICAL': \"Past Surgical History\",\n"," 'FAM/SOCHX': \"Family History/Social History\",\n"," 'DISPOSITION': \"Disposition\",\n"," 'DIAGNOSIS': \"Diagnosis\",\n"," 'EDCOURSE': \"Emergency Department Course\",\n"," 'PLAN': \"Plan\",\n"," 'LABS': \"Labs\",\n"," 'ASSESSMENT': \"Assessment\",\n"," 'ALLERGY': \"Allergy\",\n"," 'GYNHX': \"Gynecologic History\",\n"," 'EXAM': \"Exam\",\n"," 'OTHER_HISTORY': \"Other History\",\n"," 'PROCEDURES': \"Procedures\",\n"," 'IMAGING': \"Imaging\",\n"," 'IMMUNIZATIONS': \"Immunizations\"\n","}"],"metadata":{"id":"0JaXnR4LPg-E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["prompt_per_section = pd.read_csv(\"best_prompt_per_section.csv\")\n","prompt_per_section_dic = prompt_per_section.set_index('Section')['Best_Prompt'].to_dict()"],"metadata":{"id":"Zl29IAE_PA0X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["key = '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'\n","openai.api_key = key"],"metadata":{"id":"jTiJCNhXXIRv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_specific_prompt(section, dia):\n","  prompt_template = prompt_per_section_dic[section]\n","  cleaned_prompt = prompt_template[2:-1]+\"\\n\"\n","  prompt = eval(f'f\"\"\"{cleaned_prompt}\"\"\"')\n","  return prompt"],"metadata":{"id":"aRuMpVa0YE0R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_generic_prompt(section, dia):\n","  section = abb_to_full[section]\n","  generic_prompt = \"\"\"Generate a summary for the section \"{section}\" in a SOAP\\\n","  note based on the provided doctor-patient dialogue.\\n\\nDialogue:\\n{dia}\\n\\n{section}\\\n","  Summary:\"\"\".format(section=section, dia=dia)\n","  return generic_prompt"],"metadata":{"id":"INM0R4y6oM8P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_pred(model, prompt, max_tokens):\n","  response = openai.ChatCompletion.create(\n","              model=model,\n","              messages=[\n","                  {\"role\": \"system\", \"content\": \"You are a smart doctor as well as a professional medical scribe with a lot of experience.\"},\n","                  {\"role\": \"user\", \"content\": prompt},\n","              ],\n","              temperature=0.2,\n","              max_tokens=max_tokens,\n","              timeout=45,\n","              n=1,\n","              stop=None\n","          )\n","\n","  return response['choices'][0]['message']['content']"],"metadata":{"id":"oj3G1O7QWkSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = #\"gpt-3.5-turbo\" # \"gpt-4\" #use with the model you want"],"metadata":{"id":"H0HQe4IsWnvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainA[f'{model}_specific'] = trainA.apply(lambda row: get_pred(model, get_specific_prompt(row['section_header'], row['dialogue']), max_tokens[row['section_header']]), axis=1)"],"metadata":{"id":"zWNnsVjQiDDi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainA[f'{model}_generic'] = trainA.apply(lambda row: get_pred(model, get_generic_prompt(row['section_header'], row['dialogue']), max_tokens[row['section_header']]), axis=1)"],"metadata":{"id":"pjVUMqpJTOZ9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainA.to_csv(\"specific_generic_all_data.csv\")"],"metadata":{"id":"vfbg8-qCsOrW"},"execution_count":null,"outputs":[]}]}