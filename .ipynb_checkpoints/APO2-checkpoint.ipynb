{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "j7-XxAqmI2NT",
   "metadata": {
    "id": "j7-XxAqmI2NT"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install openai\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install rouge\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477749b6-e58c-44e2-97ab-8f496f40207a",
   "metadata": {
    "id": "477749b6-e58c-44e2-97ab-8f496f40207a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from metrics import Rouge, AutomaticNgramEval, AutomaticFactEval\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc3f10",
   "metadata": {
    "id": "0edc3f10"
   },
   "outputs": [],
   "source": [
    "# openai.organization = \n",
    "# OPENAI_API_KEY = \n",
    "# os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M6h-G4fAIg9B",
   "metadata": {
    "id": "M6h-G4fAIg9B"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"TaskA-TrainingSet.csv\")\n",
    "eval_df = pd.read_csv(\"TaskA-ValidationSet.csv\")\n",
    "train_df.rename(columns={'dialogue': 'Conv_snippet'}, inplace=True)\n",
    "eval_df.rename(columns={'dialogue': 'Conv_snippet'}, inplace=True)\n",
    "train_df.rename(columns={'section_text': 'summary'}, inplace=True)\n",
    "eval_df.rename(columns={'section_text': 'summary'}, inplace=True)\n",
    "train_df.rename(columns={'section_header': 'section'}, inplace=True)\n",
    "eval_df.rename(columns={'section_header': 'section'}, inplace=True)\n",
    "#what about test_df? it was in your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44752f78-6731-446c-a261-494b224fbe72",
   "metadata": {
    "id": "44752f78-6731-446c-a261-494b224fbe72"
   },
   "outputs": [],
   "source": [
    "target_section = 'EXAM'\n",
    "#'OTHER_HISTORY',\n",
    "# 'CC',\n",
    "# 'DIAGNOSIS',\n",
    "# 'FAM/SOCHX',\n",
    "# 'MEDICATIONS',\n",
    "# 'PROCEDURES',\n",
    "# 'ALLERGY',\n",
    "# 'GENHX',\n",
    "# 'ROS', '\n",
    "# PASTMEDICALHX',\n",
    "#  'PASTSURGICAL',\n",
    "#  'DISPOSITION',\n",
    "# 'EDCOURSE', '\n",
    "# PLAN',\n",
    "#  'LABS',\n",
    "# 'ASSESSMENT',\n",
    "# 'GYNHX',\n",
    "# 'IMAGING',\n",
    "# 'IMMUNIZATIONS'\n",
    "\n",
    "train_df = train_df[train_df['section']==target_section]\n",
    "eval_df = eval_df[eval_df['section']==target_section]\n",
    "# test_df = test_df[test_df['section']==target_section]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7a4ad",
   "metadata": {
    "id": "24c7a4ad"
   },
   "outputs": [],
   "source": [
    "logging = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc2039-1520-4399-a9c0-98373d95a089",
   "metadata": {
    "id": "82fc2039-1520-4399-a9c0-98373d95a089"
   },
   "outputs": [],
   "source": [
    "summarize_raw_instruction = \"\"\"[target_trainable_instruction]\n",
    "[target_trainable_few_shot_examples]\n",
    "\n",
    "SOAP note section:\n",
    "[section]\n",
    "Conversation snippet:\n",
    "[Conv_snippet]\n",
    "\n",
    "Output your summary.\n",
    "Return the output as a dictionary object, adhering to the following structure:\n",
    "{\"summary\": ...}\n",
    "Please provide your response solely in the dictionary format without including any additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451697be-515c-4ae7-9126-902564b22ebb",
   "metadata": {
    "id": "451697be-515c-4ae7-9126-902564b22ebb"
   },
   "outputs": [],
   "source": [
    "#p0\n",
    "target_trainable_instruction = \"\"\"In this task, we ask for your expertise in writing SOAP notes from the doctor-patient conversation.\n",
    "Mainly we provide the target section in the SOAP note and the conversation snippet.\n",
    "We need you to generate a summary for the respective snippet.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#gradient\n",
    "training_prompt_forward = \"\"\"In this task, you need to provide suggestions to modify the instruction in our SOAP notes writing system, which uses a model to generate SOAP notes from the doctor-patient conversation according to manually created instructions.\n",
    "Specifically, we feed the AI a conversation snippet and the target section in the SOAP note and ask it to generate the corresponding summary.\n",
    "But we found that the instruction in the current system is not perfect, so we need you to modify the instruction for this model to improve our system.\n",
    "\n",
    "The instruction now in our rating system:\n",
    "[target_trainable_instruction]\n",
    "SOAP note section for summary:\n",
    "[section]\n",
    "Conversation snippet for the model:\n",
    "[Conv_snippet]\n",
    "Current AI summary:\n",
    "[AI_summary]\n",
    "Reference summary:\n",
    "[label_summary]\n",
    "\n",
    "Here are some of the requirements you need to be aware of when suggesting the instruction modification in our system:\n",
    "1) For better generalization, what you suggest should be abstracted as high-level criteria as much as possible instead of only describing the details\n",
    "2) We will improve the instructions based on your suggestions. If I re-provide the system with the conversation snippet and the target section in the SOAP note, it needs to be able to generate the reference summary using your new suggested instructions.\n",
    "3) The instruction now in our system is for the zero-shot setting, don't try to add any examples to the instruction.\n",
    "4) We are currently only focusing on this target section, so you don't need to consider the situation of other sections in the SOAP note, just optimize the instructions completely for this section.\n",
    "\n",
    "Let's think step by step. First, output your reasons for why the current instruction in the system cannot generate the correct reference summary, then output your suggestions to modify the instruction for our system.\n",
    "Return the output as a dictionary object, adhering to the following structure:\n",
    "{\"reasons\": ..., \"suggestions\": ...}\n",
    "Ensure the 'suggestions' only includes text but not a list. Please provide your response solely in the dictionary format without including any additional text.\n",
    "\"\"\"\n",
    "\n",
    "#delta\n",
    "training_prompt_backward_prefix = \"\"\"In this task, you need to provide suggestions to modify the instruction in our SOAP notes writing system, which uses a model to generate SOAP notes from the doctor-patient conversation according to manually created instructions.\n",
    "Specifically, we feed the AI a conversation snippet and the target section in the SOAP note and ask it to generate the corresponding summary.\n",
    "But we found that the instruction in the current system is not perfect, so we need you to modify the instruction for this model to improve our system.\n",
    "\n",
    "The instruction now in our system:\n",
    "[target_trainable_instruction]\n",
    "\"\"\"\n",
    "\n",
    "#delta\n",
    "training_prompt_backward_suggestions = \"\"\"Suggestions from summary [i]:\n",
    "[suggestions]\n",
    "\"\"\"\n",
    "\n",
    "#delta\n",
    "training_prompt_backward_suffix = \"\"\"\n",
    "Here are some of the requirements you need to be aware of when modifying the instruction in our system:\n",
    "1) For better generalization, what you suggest should be abstracted as high-level criteria as much as possible instead of only describing the details\n",
    "2) We will improve the instructions based on your suggestions. If I re-provide the system with the conversation snippet and the target section in the SOAP note, it needs to be able to generate the reference summary using your new suggested instructions.\n",
    "3) The instruction now in our system is for the zero-shot setting, don't try to add any examples to the instruction.\n",
    "4) We are currently only focusing on this target section, so you don't need to consider the situation of other sections in the SOAP note, just optimize the instructions completely for this section.\n",
    "\n",
    "Let's think step by step. First, briefly summarize the suggestions of all the data to get a final suggestion containing only the highest priority requirement, then output your modified instruction for our system based on the final suggestion.\n",
    "Return the output as a dictionary object, adhering to the following structure:\n",
    "{\"final suggestion\": ..., \"new instruction\": ...}\n",
    "Please provide your response solely in the dictionary format without including any additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a6ab4-eb12-4d0c-9df4-c9d81ac280c2",
   "metadata": {
    "id": "fc2a6ab4-eb12-4d0c-9df4-c9d81ac280c2"
   },
   "outputs": [],
   "source": [
    "def dataloader(train_df, bsz,\n",
    "               target_trainable_instruction, rating_raw_instruction,\n",
    "               target_trainable_few_shot_examples, do_few_shot,\n",
    "               ngram_eval, factev,\n",
    "               sample_mode='random'):\n",
    "\n",
    "    #samples at random bsz amount of rows\n",
    "    if sample_mode == 'random':\n",
    "        sampled_data = train_df.sample(n=bsz)\n",
    "\n",
    "    if sample_mode == 'hard_negative':\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"eval results on all TRAIN DATA because of hard_negative sampling\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        eval_dict = eval_loop(train_df, target_trainable_instruction, rating_raw_instruction,\n",
    "                              target_trainable_few_shot_examples, do_few_shot,\n",
    "                              ngram_eval, factev, eval_training_step=True)\n",
    "\n",
    "        # Find indices with different values\n",
    "        different_indices = [i for i in range(len(eval_dict['labels'])) if eval_dict['labels'][i] != eval_dict['preds'][i]]\n",
    "        print('hard_negative target datapoints:', different_indices)\n",
    "\n",
    "        sampled_data = train_df.sample(n=bsz, weights=weights)\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d8367-fed6-41be-bcc8-17bfa936d051",
   "metadata": {
    "id": "fd4d8367-fed6-41be-bcc8-17bfa936d051"
   },
   "outputs": [],
   "source": [
    "# input will be p0, x --> y^\n",
    "def do_summarize(target_trainable_instruction, rating_raw_instruction, section, Conv_snippet,\n",
    "              target_trainable_few_shot_examples='', do_few_shot=False):\n",
    "    instruction = rating_raw_instruction.replace('[target_trainable_instruction]', target_trainable_instruction) #p0\n",
    "    if do_few_shot:\n",
    "        instruction = instruction.replace('[target_trainable_few_shot_examples]', target_trainable_few_shot_examples)\n",
    "    else:\n",
    "        instruction = instruction.replace('[target_trainable_few_shot_examples]', '')\n",
    "    instruction = instruction.replace('[section]', section) #x\n",
    "    instruction = instruction.replace('[Conv_snippet]', Conv_snippet) #x\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",#gpt-3.5-turbo-16k\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    summary = json.loads(response[\"choices\"][0][\"message\"][\"content\"], strict=False)['summary'] #y^\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400273a2-95e6-45a5-8622-367908e42b76",
   "metadata": {
    "id": "400273a2-95e6-45a5-8622-367908e42b76"
   },
   "outputs": [],
   "source": [
    "#logs training\n",
    "def eval_log(logging, epoch, eval_dict):\n",
    "    print('epoch:', epoch)\n",
    "\n",
    "    # Check if the epoch exists in the logging dictionary\n",
    "    if 'epoch'+str(epoch) not in logging:\n",
    "        logging['epoch'+str(epoch)]= {}  # Create a new dictionary for the epoch\n",
    "\n",
    "    for k, v in eval_dict.items():\n",
    "        logging['epoch'+str(epoch)][k] = v\n",
    "        if k != 'labels' and k != 'preds':\n",
    "            print('\\t', k, v)\n",
    "\n",
    "def eval_one_step(eval_data, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples='', do_few_shot=False):\n",
    "    section = eval_data['section']\n",
    "    Conv_snippet = eval_data['Conv_snippet']\n",
    "\n",
    "    # get the model's rating on training data before training\n",
    "    curr_summary = do_summarize(target_trainable_instruction,\n",
    "                                summarize_raw_instruction,\n",
    "                                section, Conv_snippet,\n",
    "                                target_trainable_few_shot_examples, do_few_shot)\n",
    "\n",
    "    return curr_summary\n",
    "\n",
    "def eval_loop(eval_df, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples, do_few_shot, ngram_eval, factev, eval_training_step=False):\n",
    "    summary_gpt = []\n",
    "    summary_doctor = []\n",
    "    for eval_step in tqdm(range(eval_df.shape[0]), desc=\"Evaluation\"):\n",
    "        eval_data = eval_df.iloc[eval_step]\n",
    "        try:\n",
    "            curr_summary = eval_one_step(eval_data, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples, do_few_shot)\n",
    "            summary_gpt.append(curr_summary)\n",
    "            summary_doctor.append(eval_df.iloc[eval_step]['summary'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # eval generated critique\n",
    "    eval_dict = ngram_eval.run_all_evaluation(summary_doctor, summary_gpt)\n",
    "    UMLS_dict = factev.run_source_concept_faithfulness(ref_sums = summary_doctor, gen_sums = summary_gpt)\n",
    "    del UMLS_dict['pred_concepts_term']\n",
    "    del UMLS_dict['pred_concepts_cuis']\n",
    "    eval_dict.update(UMLS_dict)\n",
    "\n",
    "    eval_dict = {'summary_'+k: round(v, 4) for k, v in eval_dict.items()}\n",
    "\n",
    "    eval_dict['labels'] = summary_doctor\n",
    "    eval_dict['preds'] = summary_gpt\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681b9b6-f381-43c1-9fe8-0e910f712a37",
   "metadata": {
    "id": "f681b9b6-f381-43c1-9fe8-0e910f712a37"
   },
   "outputs": [],
   "source": [
    "def training_forward_step(training_prompt_forward, target_trainable_instruction,\n",
    "                          section, Conv_snippet,\n",
    "                          AI_summary,\n",
    "                          label_summary,\n",
    "                          learning_temperature_rate=0):\n",
    "    instruction = training_prompt_forward.replace('[target_trainable_instruction]', target_trainable_instruction)\n",
    "    instruction = instruction.replace('[section]', section)\n",
    "    instruction = instruction.replace('[Conv_snippet]', Conv_snippet)\n",
    "    instruction = instruction.replace('[AI_summary]', AI_summary)\n",
    "    instruction = instruction.replace('[label_summary]', label_summary)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\", #gpt-4\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction}\n",
    "        ],\n",
    "        temperature=learning_temperature_rate\n",
    "    )\n",
    "\n",
    "    suggestions = json.loads(response[\"choices\"][0][\"message\"][\"content\"], strict=False)['suggestions']\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "def training_backward_step(training_prompt_backward_prefix,\n",
    "                           training_prompt_backward_suggestions,\n",
    "                           training_prompt_backward_suffix,\n",
    "                           target_trainable_instruction,\n",
    "                           bsz, bsz_suggestion,\n",
    "                           learning_temperature_rate=0):\n",
    "    # make backward instruction with prefix, suggestions, and suffix\n",
    "    instruction = training_prompt_backward_prefix.replace('[target_trainable_instruction]', target_trainable_instruction) #p0\n",
    "    for i in range(bsz): #g\n",
    "        suggestions_instruction = training_prompt_backward_suggestions.replace('[i]', str(i+1))\n",
    "        suggestions_instruction = suggestions_instruction.replace('[suggestions]', bsz_suggestion[i]['suggestions'])\n",
    "        instruction = instruction + suggestions_instruction\n",
    "    instruction = instruction + training_prompt_backward_suffix\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\", #gpt-4\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction}\n",
    "        ],\n",
    "        temperature=learning_temperature_rate\n",
    "    )\n",
    "\n",
    "    response = json.loads(response[\"choices\"][0][\"message\"][\"content\"], strict=False)\n",
    "\n",
    "    new_target_trainable_instruction = response['new instruction']\n",
    "    final_suggestion = response['final suggestion']\n",
    "    print(\"final suggestion in this step: \", final_suggestion)\n",
    "\n",
    "    return new_target_trainable_instruction\n",
    "\n",
    "def train_one_step(epoch, step, training_data, bsz, target_trainable_instruction,\n",
    "                   summarize_raw_instruction,\n",
    "                   logging, learning_temperature_rate=0):\n",
    "\n",
    "    # get forward suggestions (cal loss)\n",
    "    bsz_suggestions = []\n",
    "    for i in tqdm(range(bsz), desc=\"batch cal loss\"):\n",
    "        section = training_data.iloc[i]['section'] #x\n",
    "        Conv_snippet = training_data.iloc[i]['Conv_snippet'] #x\n",
    "        label_summary = training_data.iloc[i]['summary'] #y\n",
    "\n",
    "        # get the model's summary on training data before training --> y^\n",
    "        AI_summary = do_summarize(target_trainable_instruction,\n",
    "                                  summarize_raw_instruction,\n",
    "                                  section, Conv_snippet)\n",
    "\n",
    "        # get suggestions for every data in batch --> input: p0, x, y^, y --> g\n",
    "        suggestions = training_forward_step(training_prompt_forward, target_trainable_instruction, section,\n",
    "                                     Conv_snippet, AI_summary, label_summary,\n",
    "                                     learning_temperature_rate)\n",
    "\n",
    "        bsz_suggestions.append({'label_summary': label_summary,\n",
    "                                'AI_summary': AI_summary,\n",
    "                                'suggestions': suggestions})\n",
    "\n",
    "    # make backward update\n",
    "    new_target_trainable_instruction = training_backward_step(training_prompt_backward_prefix,\n",
    "                                                              training_prompt_backward_suggestions,\n",
    "                                                              training_prompt_backward_suffix,\n",
    "                                                              target_trainable_instruction,\n",
    "                                                              bsz,\n",
    "                                                              bsz_suggestions,\n",
    "                                                              learning_temperature_rate)\n",
    "    #update to get new target_trainable_instruction\n",
    "    target_trainable_instruction = new_target_trainable_instruction\n",
    "    is_updated = True\n",
    "\n",
    "    return target_trainable_instruction, is_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4334563-0e23-441d-8d1c-20655d9e5302",
   "metadata": {
    "id": "d4334563-0e23-441d-8d1c-20655d9e5302"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_df, eval_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "               logging, ngram_eval, factev,\n",
    "               target_trainable_few_shot_examples='', do_few_shot=False,\n",
    "               EPOCH=1, steps_per_epoch=5, bsz=10,\n",
    "               eval_at_beginning=False, dataloader_sample_mode='random', learning_temperature_rate=0):\n",
    "\n",
    "    #does evaluatoin on the original prompt before any training\n",
    "    if eval_at_beginning:\n",
    "        print(\"the init target_trainable_instruction is:\")\n",
    "        print(target_trainable_instruction)\n",
    "        if do_few_shot:\n",
    "            print(\"the init target_trainable_few_shot_examples is:\")\n",
    "            print(target_trainable_few_shot_examples)\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"eval results on all TRAINING DATA in the beginning\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        eval_dict = eval_loop(train_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                              target_trainable_few_shot_examples, do_few_shot,\n",
    "                              ngram_eval, factev, eval_training_step=False)\n",
    "        eval_log(logging, -1, eval_dict)\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"eval results on all EVAL DATA in the beginning\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        eval_dict = eval_loop(eval_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                              target_trainable_few_shot_examples, do_few_shot,\n",
    "                              ngram_eval, factev, eval_training_step=False)\n",
    "        eval_log(logging, -1, eval_dict)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        print(str(epoch), \"EPOCH BEGIN--------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH BEGIN--------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH BEGIN--------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        # Check if the epoch exists in the logging dictionary\n",
    "        if 'epoch'+str(epoch) not in logging:\n",
    "            logging['epoch'+str(epoch)] = {}  # Create a new dictionary for the epoch\n",
    "\n",
    "        any_change_in_this_epoch = False\n",
    "\n",
    "        for train_step in tqdm(range(steps_per_epoch), desc=\"Training\"):\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            print(\"START NEW TRAINING STEP\")\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "\n",
    "            # try:\n",
    "            # load training data for the epoch\n",
    "            training_data = dataloader(train_df, bsz,\n",
    "                                       target_trainable_instruction, summarize_raw_instruction,\n",
    "                                       target_trainable_few_shot_examples, do_few_shot,\n",
    "                                       ngram_eval, factev,\n",
    "                                       dataloader_sample_mode)\n",
    "\n",
    "            #-----------\n",
    "            print(\"training metrics: before training step\")\n",
    "            eval_dict = eval_loop(training_data, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=True)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "            #-----------\n",
    "\n",
    "            print('training section:', training_data.index.tolist())\n",
    "\n",
    "            #train the \"instruction\"\n",
    "            if not do_few_shot:\n",
    "                target_trainable_instruction, is_updated = train_one_step(epoch, train_step, training_data, bsz,\n",
    "                                                                          target_trainable_instruction,\n",
    "                                                                          summarize_raw_instruction,\n",
    "                                                                          logging, learning_temperature_rate=learning_temperature_rate)\n",
    "\n",
    "            #train the few-shot-examples\n",
    "            if do_few_shot:\n",
    "                target_trainable_few_shot_examples = train_one_step_for_few_shot_example(epoch, train_step,\n",
    "                                                                                         training_data,\n",
    "                                                                                         bsz,\n",
    "                                                                                         target_trainable_instruction,\n",
    "                                                                                         target_trainable_few_shot_examples,\n",
    "                                                                                         summarize_raw_instruction,\n",
    "                                                                                         logging,\n",
    "                                                                                         learning_temperature_rate=0)\n",
    "                is_updated = True\n",
    "\n",
    "            if is_updated:\n",
    "                any_change_in_this_epoch = True\n",
    "\n",
    "            #-----------\n",
    "            print(\"training metrics: after training step\")\n",
    "            eval_dict = eval_loop(training_data, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=True)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "            #-----------\n",
    "            # except:\n",
    "            #     print('Encounter some errors from OpenAI API')\n",
    "            #     # print('Encounter some errors from OpenAI API, start to sleep 60s...')\n",
    "            #     # time.sleep(60)\n",
    "            #     # print('End sleep, resume the training')\n",
    "            #     continue\n",
    "\n",
    "\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            print(\"END THIS TRAINING STEP\")\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "\n",
    "        print(str(epoch), \"EPOCH END----------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH END----------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH END----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        # do eval\n",
    "        if any_change_in_this_epoch:\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            print(\"eval results on all TRAINING DATA for EPOCH\", str(epoch))\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            eval_dict = eval_loop(train_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=False)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            print(\"eval results on all EVAL DATA for EPOCH\", str(epoch))\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            eval_dict = eval_loop(eval_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=False)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "\n",
    "            print(\"after curr epoch, the target_trainable_instruction is:\")\n",
    "            print(target_trainable_instruction)\n",
    "            if do_few_shot:\n",
    "                print(\"after curr epoch, the target_trainable_few_shot_examples is:\")\n",
    "                print(target_trainable_few_shot_examples)\n",
    "\n",
    "    return target_trainable_instruction, target_trainable_few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d943fc2-66f9-454b-be6c-c3cc2096a7b8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625,
     "referenced_widgets": [
      "7a2a58c4b42245a9bbce207c35eb3c5b",
      "f518599ca8f9412c905cbb3361e7858d",
      "4e3e54e599c14770b4f9448e2ff93f26",
      "37a3bfdc941d4eb2833c6c5e1bc2cec3",
      "a144e9d4ae314a4fa0363da89405f531",
      "fa1cc66ee1034b8aae29e2157f18e818",
      "ec704387488e48699b86a94f42d37ec3",
      "fd41cfa5adbe4466971fcde65716dbf6",
      "bafcbd4eaa7d4d22a6a841bcf121ec2d",
      "1a566cff0163404e9653908bb86190c9",
      "14f4bcf04cda45dca9938ed5d6183db2"
     ]
    },
    "executionInfo": {
     "elapsed": 144,
     "status": "error",
     "timestamp": 1696620325065,
     "user": {
      "displayName": "Ahmed Jaafar",
      "userId": "01925140053924734789"
     },
     "user_tz": 240
    },
    "id": "1d943fc2-66f9-454b-be6c-c3cc2096a7b8",
    "outputId": "dac8fc9a-4b29-4b1f-8b37-a2c3780792cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the init target_trainable_instruction is:\n",
      "In this task, we ask for your expertise in writing SOAP notes from the doctor-patient conversation.\n",
      "Mainly we provide the target section in the SOAP note and the conversation snippet.\n",
      "We need you to generate a summary for the respective snippet.\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------------------\n",
      "eval results on all TRAINING DATA in the beginning\n",
      "----------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a2a58c4b42245a9bbce207c35eb3c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation:   0%|          | 0/23 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2eb6adf17694>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfactev\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m target_trainable_instruction, target_trainable_few_shot_examples = train_loop(train_df, eval_df,\n\u001b[0m\u001b[1;32m      6\u001b[0m                                                                               \u001b[0mtarget_trainable_instruction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                                               \u001b[0msummarize_raw_instruction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-0d2dc8ecae7e>\u001b[0m in \u001b[0;36mtrain_loop\u001b[0;34m(train_df, eval_df, target_trainable_instruction, summarize_raw_instruction, logging, ngram_eval, factev, target_trainable_few_shot_examples, do_few_shot, EPOCH, steps_per_epoch, bsz, eval_at_beginning, dataloader_sample_mode, learning_temperature_rate)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"eval results on all TRAINING DATA in the beginning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"----------------------------------------------------------------------------------------------------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         eval_dict = eval_loop(train_df, target_trainable_instruction, summarize_raw_instruction,\n\u001b[0m\u001b[1;32m     19\u001b[0m                               \u001b[0mtarget_trainable_few_shot_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdo_few_shot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                               ngram_eval, factev, eval_training_step=False)\n",
      "\u001b[0;32m<ipython-input-13-8df85d50a2de>\u001b[0m in \u001b[0;36meval_loop\u001b[0;34m(eval_df, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples, do_few_shot, ngram_eval, factev, eval_training_step)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# eval generated critique\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0meval_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mngram_eval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_all_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msummary_doctor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_gpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0mUMLS_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfactev\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_source_concept_faithfulness\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_doctor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_sums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummary_gpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdel\u001b[0m \u001b[0mUMLS_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred_concepts_term'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/metrics.py\u001b[0m in \u001b[0;36mrun_all_evaluation\u001b[0;34m(self, ref_texts, gen_texts, use_aggregator)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_all_evaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_aggregator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_aggregator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             \u001b[0mmeteor_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_meteor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_aggregator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m             \u001b[0mrouge_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouge_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrouge_l\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_rouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_aggregator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             return {'rouge1': rouge_1, \n",
      "\u001b[0;32m/content/metrics.py\u001b[0m in \u001b[0;36mrun_rouge\u001b[0;34m(self, ref_texts, gen_texts, use_aggregator)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_rouge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_aggregator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrouge_scorer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_aggregator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_aggregator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/rouge/rouge.py\u001b[0m in \u001b[0;36mget_scores\u001b[0;34m(self, hyps, refs, avg, ignore_empty)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mavg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_avg_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/metrics.py\u001b[0m in \u001b[0;36m_get_avg_scores\u001b[0;34m(self, hyps, refs)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         avg_scores = {\n\u001b[1;32m     67\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/metrics.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         avg_scores = {\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/metrics.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mbreakpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         avg_scores = {\n\u001b[0m\u001b[1;32m     67\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "ngram_eval = AutomaticNgramEval()\n",
    "# factev = AutomaticFactEval()\n",
    "factev=None\n",
    "\n",
    "target_trainable_instruction, target_trainable_few_shot_examples = train_loop(train_df, eval_df,\n",
    "                                                                              target_trainable_instruction,\n",
    "                                                                              summarize_raw_instruction, logging,\n",
    "                                                                              ngram_eval, factev,\n",
    "                                                                              target_trainable_few_shot_examples='',\n",
    "                                                                              do_few_shot=False,\n",
    "                                                                              EPOCH=1, steps_per_epoch=5, bsz=10,\n",
    "                                                                              eval_at_beginning=True,\n",
    "                                                                              dataloader_sample_mode='random',\n",
    "                                                                              learning_temperature_rate=0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "salt",
   "language": "python",
   "name": "salt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "14f4bcf04cda45dca9938ed5d6183db2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "1a566cff0163404e9653908bb86190c9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "37a3bfdc941d4eb2833c6c5e1bc2cec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1a566cff0163404e9653908bb86190c9",
      "placeholder": "​",
      "style": "IPY_MODEL_14f4bcf04cda45dca9938ed5d6183db2",
      "value": " 23/23 [00:00&lt;00:00, 766.52it/s]"
     }
    },
    "4e3e54e599c14770b4f9448e2ff93f26": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fd41cfa5adbe4466971fcde65716dbf6",
      "max": 23,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_bafcbd4eaa7d4d22a6a841bcf121ec2d",
      "value": 23
     }
    },
    "7a2a58c4b42245a9bbce207c35eb3c5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f518599ca8f9412c905cbb3361e7858d",
       "IPY_MODEL_4e3e54e599c14770b4f9448e2ff93f26",
       "IPY_MODEL_37a3bfdc941d4eb2833c6c5e1bc2cec3"
      ],
      "layout": "IPY_MODEL_a144e9d4ae314a4fa0363da89405f531"
     }
    },
    "a144e9d4ae314a4fa0363da89405f531": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bafcbd4eaa7d4d22a6a841bcf121ec2d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "ec704387488e48699b86a94f42d37ec3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f518599ca8f9412c905cbb3361e7858d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fa1cc66ee1034b8aae29e2157f18e818",
      "placeholder": "​",
      "style": "IPY_MODEL_ec704387488e48699b86a94f42d37ec3",
      "value": "Evaluation: 100%"
     }
    },
    "fa1cc66ee1034b8aae29e2157f18e818": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fd41cfa5adbe4466971fcde65716dbf6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
