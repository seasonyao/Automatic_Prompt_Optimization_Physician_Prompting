{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2nOCQ5vmd-u"
   },
   "outputs": [],
   "source": [
    "!pip install openai==0.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HUBqb2TF61j"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mh3Ix5XJgCrj"
   },
   "outputs": [],
   "source": [
    "trainA = pd.read_csv('TaskA-TrainingSet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nMjnp_s_WwWp"
   },
   "outputs": [],
   "source": [
    "sections = trainA['section_header'].unique().tolist()\n",
    "max_tokens = {}\n",
    "\n",
    "for s in sections:\n",
    "  s_df = trainA[trainA['section_header'] == s]\n",
    "  avg_chars = s_df['section_text'].str.len().mean()\n",
    "  max_tokens[s] = int(round(avg_chars/4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0JaXnR4LPg-E"
   },
   "outputs": [],
   "source": [
    "abb_to_full = {\n",
    " 'GENHX': \"History of Present Illness\",\n",
    " 'ROS': \"Review of Systems\",\n",
    " 'PASTMEDICALHX': \"Past Medical History\",\n",
    " 'MEDICATIONS': \"Medications\",\n",
    " 'CC': \"Chief Complaint\",\n",
    " 'PASTSURGICAL': \"Past Surgical History\",\n",
    " 'FAM/SOCHX': \"Family History/Social History\",\n",
    " 'DISPOSITION': \"Disposition\",\n",
    " 'DIAGNOSIS': \"Diagnosis\",\n",
    " 'EDCOURSE': \"Emergency Department Course\",\n",
    " 'PLAN': \"Plan\",\n",
    " 'LABS': \"Labs\",\n",
    " 'ASSESSMENT': \"Assessment\",\n",
    " 'ALLERGY': \"Allergy\",\n",
    " 'GYNHX': \"Gynecologic History\",\n",
    " 'EXAM': \"Exam\",\n",
    " 'OTHER_HISTORY': \"Other History\",\n",
    " 'PROCEDURES': \"Procedures\",\n",
    " 'IMAGING': \"Imaging\",\n",
    " 'IMMUNIZATIONS': \"Immunizations\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl29IAE_PA0X"
   },
   "outputs": [],
   "source": [
    "prompt_per_section = pd.read_csv(\"best_prompt_per_section.csv\")\n",
    "prompt_per_section_dic = prompt_per_section.set_index('Section')['Best_Prompt'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jTiJCNhXXIRv"
   },
   "outputs": [],
   "source": [
    "openai.api_key = #insert API key here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aRuMpVa0YE0R"
   },
   "outputs": [],
   "source": [
    "def get_specific_prompt(section, dia):\n",
    "  prompt_template = prompt_per_section_dic[section]\n",
    "  cleaned_prompt = prompt_template[2:-1]+\"\\n\"\n",
    "  prompt = eval(f'f\"\"\"{cleaned_prompt}\"\"\"')\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "INM0R4y6oM8P"
   },
   "outputs": [],
   "source": [
    "def get_generic_prompt(section, dia):\n",
    "  section = abb_to_full[section]\n",
    "  generic_prompt = \"\"\"Generate a summary for the section \"{section}\" in a SOAP\\\n",
    "  note based on the provided doctor-patient dialogue.\\n\\nDialogue:\\n{dia}\\n\\n{section}\\\n",
    "  Summary:\"\"\".format(section=section, dia=dia)\n",
    "  return generic_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oj3G1O7QWkSe"
   },
   "outputs": [],
   "source": [
    "def get_pred(model, prompt, max_tokens):\n",
    "  response = openai.ChatCompletion.create(\n",
    "              model=model,\n",
    "              messages=[\n",
    "                  {\"role\": \"system\", \"content\": \"You are a smart doctor as well as a professional medical scribe with a lot of experience.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt},\n",
    "              ],\n",
    "              temperature=0.2,\n",
    "              max_tokens=max_tokens,\n",
    "              timeout=45,\n",
    "              n=1,\n",
    "              stop=None\n",
    "          )\n",
    "\n",
    "  return response['choices'][0]['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H0HQe4IsWnvW"
   },
   "outputs": [],
   "source": [
    "model = #\"gpt-3.5-turbo\" # \"gpt-4\" #use with the model you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zWNnsVjQiDDi"
   },
   "outputs": [],
   "source": [
    "trainA[f'{model}_specific'] = trainA.apply(lambda row: get_pred(model, get_specific_prompt(row['section_header'], row['dialogue']), max_tokens[row['section_header']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pjVUMqpJTOZ9"
   },
   "outputs": [],
   "source": [
    "trainA[f'{model}_generic'] = trainA.apply(lambda row: get_pred(model, get_generic_prompt(row['section_header'], row['dialogue']), max_tokens[row['section_header']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vfbg8-qCsOrW"
   },
   "outputs": [],
   "source": [
    "trainA.to_csv(\"specific_generic_all_data.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (4.8.3-jupyterhub-stable) *",
   "language": "python",
   "name": "conda-env-4.8.3-jupyterhub-stable-py"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
