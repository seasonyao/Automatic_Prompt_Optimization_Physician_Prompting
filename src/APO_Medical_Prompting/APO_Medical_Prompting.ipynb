{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477749b6-e58c-44e2-97ab-8f496f40207a",
   "metadata": {
    "id": "477749b6-e58c-44e2-97ab-8f496f40207a"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import json\n",
    "from metrics import Rouge, AutomaticNgramEval, AutomaticFactEval\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc3f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = #insert OpenAI API key here\n",
    "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "M6h-G4fAIg9B",
   "metadata": {
    "id": "M6h-G4fAIg9B"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../../data/TaskA-TrainingSet.csv\")\n",
    "eval_df = pd.read_csv(\"../../data/TaskA-ValidationSet.csv\")\n",
    "\n",
    "train_df.rename(columns={'dialogue': 'Conv_snippet'}, inplace=True)\n",
    "eval_df.rename(columns={'dialogue': 'Conv_snippet'}, inplace=True)\n",
    "train_df.rename(columns={'section_text': 'summary'}, inplace=True)\n",
    "eval_df.rename(columns={'section_text': 'summary'}, inplace=True)\n",
    "train_df.rename(columns={'section_header': 'section'}, inplace=True)\n",
    "eval_df.rename(columns={'section_header': 'section'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44752f78-6731-446c-a261-494b224fbe72",
   "metadata": {
    "id": "44752f78-6731-446c-a261-494b224fbe72"
   },
   "outputs": [],
   "source": [
    "#pick a section and uncomment it to run the code for that section\n",
    "# target_section = 'EXAM' \n",
    "# target_section ='OTHER_HISTORY' \n",
    "# target_section = 'CC' \n",
    "# target_section = 'DIAGNOSIS'\n",
    "# target_section = 'FAM/SOCHX'\n",
    "# target_section = 'MEDICATIONS'\n",
    "# target_section = 'PROCEDURES' \n",
    "# target_section = 'ALLERGY'\n",
    "# target_section = 'GENHX'\n",
    "# target_section = 'ROS'\n",
    "# target_section = 'PASTMEDICALHX'\n",
    "# target_section = 'PASTSURGICAL'\n",
    "# target_section = 'DISPOSITION'\n",
    "# target_section = 'EDCOURSE' \n",
    "# target_section = 'PLAN'\n",
    "# target_section = 'LABS' \n",
    "# target_section = 'ASSESSMENT' \n",
    "target_section = 'GYNHX'\n",
    "# target_section = 'IMAGING' \n",
    "# target_section  ='IMMUNIZATIONS' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c03c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['section']==target_section]\n",
    "eval_df = eval_df[eval_df['section']==target_section]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c7a4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc2039-1520-4399-a9c0-98373d95a089",
   "metadata": {
    "id": "82fc2039-1520-4399-a9c0-98373d95a089"
   },
   "outputs": [],
   "source": [
    "summarize_raw_instruction = \"\"\"[target_trainable_instruction]\n",
    "[target_trainable_few_shot_examples]\n",
    "\n",
    "SOAP note section:\n",
    "[section]\n",
    "Conversation snippet:\n",
    "[Conv_snippet]\n",
    "\n",
    "Output your summary.\n",
    "Return the output as a dictionary object, adhering to the following structure:\n",
    "{\"summary\": ...}\n",
    "Please provide your response solely in the dictionary format without including any additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451697be-515c-4ae7-9126-902564b22ebb",
   "metadata": {
    "id": "451697be-515c-4ae7-9126-902564b22ebb"
   },
   "outputs": [],
   "source": [
    "#p0 (initial generic prompt)\n",
    "target_trainable_instruction = \"\"\"In this task, we ask for your expertise in writing SOAP notes from the doctor-patient conversation.\n",
    "Mainly we provide the target section in the SOAP note and the conversation snippet.\n",
    "We need you to generate a summary for the respective snippet.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#gradient\n",
    "training_prompt_forward = \"\"\"In this task, you need to provide suggestions to modify the instruction in our SOAP notes writing system, which uses a model to generate SOAP notes from the doctor-patient conversation according to manually created instructions.\n",
    "Specifically, we feed the AI a conversation snippet and the target section in the SOAP note and ask it to generate the corresponding summary.\n",
    "But we found that the instruction in the current system is not perfect, so we need you to modify the instruction for this model to improve our system.\n",
    "\n",
    "The instruction now in our rating system:\n",
    "[target_trainable_instruction]\n",
    "SOAP note section for summary:\n",
    "[section]\n",
    "Conversation snippet for the model:\n",
    "[Conv_snippet]\n",
    "Current AI summary:\n",
    "[AI_summary]\n",
    "Reference summary:\n",
    "[label_summary]\n",
    "\n",
    "Here are some of the requirements you need to be aware of when suggesting the instruction modification in our system:\n",
    "1) For better generalization, what you suggest should be abstracted as high-level criteria as much as possible instead of only describing the details\n",
    "2) We will improve the instructions based on your suggestions. If I re-provide the system with the conversation snippet and the target section in the SOAP note, it needs to be able to generate the reference summary using your new suggested instructions.\n",
    "3) The instruction now in our system is for the zero-shot setting, don't try to add any examples to the instruction.\n",
    "4) We are currently only focusing on this target section, so you don't need to consider the situation of other sections in the SOAP note, just optimize the instructions completely for this section.\n",
    "\n",
    "Let's think step by step. First, output your reasons for why the current instruction in the system cannot generate the correct reference summary, then output your suggestions to modify the instruction for our system.\n",
    "Return the output as a dictionary object, adhering to the following structure:\n",
    "{\"reasons\": ..., \"suggestions\": ...}\n",
    "Ensure the 'suggestions' only includes text but not a list. Please provide your response solely in the dictionary format without including any additional text.\n",
    "\"\"\"\n",
    "\n",
    "#delta\n",
    "training_prompt_backward_prefix = \"\"\"In this task, you need to provide suggestions to modify the instruction in our SOAP notes writing system, which uses a model to generate SOAP notes from the doctor-patient conversation according to manually created instructions.\n",
    "Specifically, we feed the AI a conversation snippet and the target section in the SOAP note and ask it to generate the corresponding summary.\n",
    "But we found that the instruction in the current system is not perfect, so we need you to modify the instruction for this model to improve our system.\n",
    "\n",
    "The instruction now in our system:\n",
    "[target_trainable_instruction]\n",
    "\"\"\"\n",
    "\n",
    "#delta\n",
    "training_prompt_backward_suggestions = \"\"\"Suggestions from summary [i]:\n",
    "[suggestions]\n",
    "\"\"\"\n",
    "\n",
    "#delta\n",
    "training_prompt_backward_suffix = \"\"\"\n",
    "Here are some of the requirements you need to be aware of when modifying the instruction in our system:\n",
    "1) For better generalization, what you suggest should be abstracted as high-level criteria as much as possible instead of only describing the details\n",
    "2) We will improve the instructions based on your suggestions. If I re-provide the system with the conversation snippet and the target section in the SOAP note, it needs to be able to generate the reference summary using your new suggested instructions.\n",
    "3) The instruction now in our system is for the zero-shot setting, don't try to add any examples to the instruction.\n",
    "4) We are currently only focusing on this target section, so you don't need to consider the situation of other sections in the SOAP note, just optimize the instructions completely for this section.\n",
    "\n",
    "Let's think step by step. First, briefly summarize the suggestions of all the data to get a final suggestion containing only the highest priority requirement, then output your modified instruction for our system based on the final suggestion.\n",
    "Return the output as a dictionary object, adhering to the following structure:\n",
    "{\"final suggestion\": ..., \"new instruction\": ...}\n",
    "Please provide your response solely in the dictionary format without including any additional text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a6ab4-eb12-4d0c-9df4-c9d81ac280c2",
   "metadata": {
    "id": "fc2a6ab4-eb12-4d0c-9df4-c9d81ac280c2"
   },
   "outputs": [],
   "source": [
    "def dataloader(train_df, bsz, \n",
    "               target_trainable_instruction, rating_raw_instruction,\n",
    "               target_trainable_few_shot_examples, do_few_shot,\n",
    "               ngram_eval, factev,\n",
    "               sample_mode='random'):\n",
    "    \n",
    "    #samples at random bsz amount of rows\n",
    "    if sample_mode == 'random':\n",
    "        sampled_data = train_df.sample(n=bsz)\n",
    "\n",
    "    if sample_mode == 'hard_negative':\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"eval results on all TRAIN DATA because of hard_negative sampling\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        eval_dict = eval_loop(train_df, target_trainable_instruction, rating_raw_instruction,\n",
    "                              target_trainable_few_shot_examples, do_few_shot,\n",
    "                              ngram_eval, factev, eval_training_step=True)\n",
    "\n",
    "        # Find indices with different values\n",
    "        different_indices = [i for i in range(len(eval_dict['labels'])) if eval_dict['labels'][i] != eval_dict['preds'][i]]\n",
    "        print('hard_negative target datapoints:', different_indices)\n",
    "\n",
    "        sampled_data = train_df.sample(n=bsz, weights=weights)\n",
    "\n",
    "    return sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4d8367-fed6-41be-bcc8-17bfa936d051",
   "metadata": {
    "id": "fd4d8367-fed6-41be-bcc8-17bfa936d051"
   },
   "outputs": [],
   "source": [
    "# input will be p0, x --> y^\n",
    "def do_summarize(target_trainable_instruction, rating_raw_instruction, section, Conv_snippet,\n",
    "              target_trainable_few_shot_examples='', do_few_shot=False):\n",
    "    instruction = rating_raw_instruction.replace('[target_trainable_instruction]', target_trainable_instruction) #p0\n",
    "    if do_few_shot:\n",
    "        instruction = instruction.replace('[target_trainable_few_shot_examples]', target_trainable_few_shot_examples)\n",
    "    else:\n",
    "        instruction = instruction.replace('[target_trainable_few_shot_examples]', '')\n",
    "    instruction = instruction.replace('[section]', section) #x\n",
    "    instruction = instruction.replace('[Conv_snippet]', Conv_snippet) #x\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",#gpt-3.5-turbo-16k\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction}\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    summary = json.loads(response[\"choices\"][0][\"message\"][\"content\"], strict=False)['summary'] #y^\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400273a2-95e6-45a5-8622-367908e42b76",
   "metadata": {
    "id": "400273a2-95e6-45a5-8622-367908e42b76"
   },
   "outputs": [],
   "source": [
    "#logs training\n",
    "def eval_log(logging, epoch, eval_dict):\n",
    "    print('epoch:', epoch)\n",
    "\n",
    "    # Check if the epoch exists in the logging dictionary\n",
    "    if 'epoch'+str(epoch) not in logging:\n",
    "        logging['epoch'+str(epoch)]= {}  # Create a new dictionary for the epoch\n",
    "\n",
    "    for k, v in eval_dict.items():\n",
    "        logging['epoch'+str(epoch)][k] = v\n",
    "        if k != 'labels' and k != 'preds':\n",
    "            print('\\t', k, v)\n",
    "\n",
    "def eval_one_step(eval_data, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples='', do_few_shot=False):\n",
    "    section = eval_data['section']\n",
    "    Conv_snippet = eval_data['Conv_snippet']\n",
    "\n",
    "    # get the model's rating on training data before training\n",
    "    curr_summary = do_summarize(target_trainable_instruction,\n",
    "                                summarize_raw_instruction,\n",
    "                                section, Conv_snippet,\n",
    "                                target_trainable_few_shot_examples, do_few_shot)\n",
    "\n",
    "    return curr_summary\n",
    "\n",
    "def eval_loop(eval_df, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples, do_few_shot, ngram_eval, factev, eval_training_step=False):\n",
    "    summary_gpt = []\n",
    "    summary_doctor = []\n",
    "    for eval_step in tqdm(range(eval_df.shape[0]), desc=\"Evaluation\"):\n",
    "        eval_data = eval_df.iloc[eval_step]\n",
    "        try:\n",
    "            curr_summary = eval_one_step(eval_data, target_trainable_instruction, summarize_raw_instruction, target_trainable_few_shot_examples, do_few_shot)\n",
    "            summary_gpt.append(curr_summary)\n",
    "            summary_doctor.append(eval_df.iloc[eval_step]['summary'])\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    # eval generated critique\n",
    "    eval_dict = ngram_eval.run_all_evaluation(summary_doctor, summary_gpt)\n",
    "    # UMLS_dict = factev.run_source_concept_faithfulness(ref_sums = summary_doctor, gen_sums = summary_gpt)\n",
    "    # del UMLS_dict['pred_concepts_term']\n",
    "    # del UMLS_dict['pred_concepts_cuis']\n",
    "    # eval_dict.update(UMLS_dict)\n",
    "\n",
    "    eval_dict = {'summary_'+k: round(v, 4) for k, v in eval_dict.items()}\n",
    "\n",
    "    eval_dict['labels'] = summary_doctor\n",
    "    eval_dict['preds'] = summary_gpt\n",
    "\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681b9b6-f381-43c1-9fe8-0e910f712a37",
   "metadata": {
    "id": "f681b9b6-f381-43c1-9fe8-0e910f712a37"
   },
   "outputs": [],
   "source": [
    "def training_forward_step(training_prompt_forward, target_trainable_instruction,\n",
    "                          section, Conv_snippet,\n",
    "                          AI_summary,\n",
    "                          label_summary,\n",
    "                          learning_temperature_rate=0):\n",
    "    instruction = training_prompt_forward.replace('[target_trainable_instruction]', target_trainable_instruction)\n",
    "    instruction = instruction.replace('[section]', section)\n",
    "    instruction = instruction.replace('[Conv_snippet]', Conv_snippet)\n",
    "    instruction = instruction.replace('[AI_summary]', AI_summary)\n",
    "    instruction = instruction.replace('[label_summary]', label_summary)\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\", #gpt-4\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction}\n",
    "        ],\n",
    "        temperature=learning_temperature_rate\n",
    "    )\n",
    "\n",
    "    suggestions = json.loads(response[\"choices\"][0][\"message\"][\"content\"], strict=False)['suggestions']\n",
    "\n",
    "    return suggestions\n",
    "\n",
    "def training_backward_step(training_prompt_backward_prefix,\n",
    "                           training_prompt_backward_suggestions,\n",
    "                           training_prompt_backward_suffix,\n",
    "                           target_trainable_instruction,\n",
    "                           bsz, bsz_suggestion,\n",
    "                           learning_temperature_rate=0):\n",
    "    # make backward instruction with prefix, suggestions, and suffix\n",
    "    instruction = training_prompt_backward_prefix.replace('[target_trainable_instruction]', target_trainable_instruction) #p0\n",
    "    for i in range(bsz): #g\n",
    "        suggestions_instruction = training_prompt_backward_suggestions.replace('[i]', str(i+1))\n",
    "        suggestions_instruction = suggestions_instruction.replace('[suggestions]', bsz_suggestion[i]['suggestions'])\n",
    "        instruction = instruction + suggestions_instruction\n",
    "    instruction = instruction + training_prompt_backward_suffix\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\", #gpt-4\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": instruction}\n",
    "        ],\n",
    "        temperature=learning_temperature_rate\n",
    "    )\n",
    "\n",
    "    response = json.loads(response[\"choices\"][0][\"message\"][\"content\"], strict=False)\n",
    "\n",
    "    new_target_trainable_instruction = response['new instruction']\n",
    "    final_suggestion = response['final suggestion']\n",
    "    print(\"final suggestion in this step: \", final_suggestion)\n",
    "\n",
    "    return new_target_trainable_instruction\n",
    "\n",
    "def train_one_step(epoch, step, training_data, bsz, target_trainable_instruction,\n",
    "                   summarize_raw_instruction,\n",
    "                   logging, learning_temperature_rate=0):\n",
    "\n",
    "    # get forward suggestions (cal loss)\n",
    "    bsz_suggestions = []\n",
    "    for i in tqdm(range(bsz), desc=\"batch cal loss\"):\n",
    "        section = training_data.iloc[i]['section'] #x\n",
    "        Conv_snippet = training_data.iloc[i]['Conv_snippet'] #x\n",
    "        label_summary = training_data.iloc[i]['summary'] #y\n",
    "\n",
    "        # get the model's summary on training data before training --> y^\n",
    "        AI_summary = do_summarize(target_trainable_instruction,\n",
    "                                  summarize_raw_instruction,\n",
    "                                  section, Conv_snippet)\n",
    "\n",
    "        # get suggestions for every data in batch --> input: p0, x, y^, y --> g\n",
    "        suggestions = training_forward_step(training_prompt_forward, target_trainable_instruction, section,\n",
    "                                     Conv_snippet, AI_summary, label_summary,\n",
    "                                     learning_temperature_rate)\n",
    "\n",
    "        bsz_suggestions.append({'label_summary': label_summary,\n",
    "                                'AI_summary': AI_summary,\n",
    "                                'suggestions': suggestions})\n",
    "\n",
    "    # make backward update\n",
    "    new_target_trainable_instruction = training_backward_step(training_prompt_backward_prefix,\n",
    "                                                              training_prompt_backward_suggestions,\n",
    "                                                              training_prompt_backward_suffix,\n",
    "                                                              target_trainable_instruction,\n",
    "                                                              bsz,\n",
    "                                                              bsz_suggestions,\n",
    "                                                              learning_temperature_rate)\n",
    "    #update to get new target_trainable_instruction\n",
    "    target_trainable_instruction = new_target_trainable_instruction\n",
    "    is_updated = True\n",
    "\n",
    "    return target_trainable_instruction, is_updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4334563-0e23-441d-8d1c-20655d9e5302",
   "metadata": {
    "id": "d4334563-0e23-441d-8d1c-20655d9e5302"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_df, eval_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "               logging, ngram_eval, factev,\n",
    "               target_trainable_few_shot_examples='', do_few_shot=False,\n",
    "               EPOCH=1, steps_per_epoch=5, bsz=10,\n",
    "               eval_at_beginning=False, dataloader_sample_mode='random', learning_temperature_rate=0):\n",
    "    \n",
    "    #does evaluation on the original prompt before any training\n",
    "    if eval_at_beginning:\n",
    "        print(\"the init target_trainable_instruction is:\")\n",
    "        print(target_trainable_instruction)\n",
    "        if do_few_shot:\n",
    "            print(\"the init target_trainable_few_shot_examples is:\")\n",
    "            print(target_trainable_few_shot_examples)\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"eval results on all TRAINING DATA in the beginning\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        eval_dict = eval_loop(train_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                              target_trainable_few_shot_examples, do_few_shot,\n",
    "                              ngram_eval, factev, eval_training_step=False)\n",
    "        eval_log(logging, -1, eval_dict)\n",
    "\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        print(\"eval results on all EVAL DATA in the beginning\")\n",
    "        print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "        eval_dict = eval_loop(eval_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                              target_trainable_few_shot_examples, do_few_shot,\n",
    "                              ngram_eval, factev, eval_training_step=False)\n",
    "        eval_log(logging, -1, eval_dict)\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        print(str(epoch), \"EPOCH BEGIN--------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH BEGIN--------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH BEGIN--------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        # Check if the epoch exists in the logging dictionary\n",
    "        if 'epoch'+str(epoch) not in logging:\n",
    "            logging['epoch'+str(epoch)] = {}  # Create a new dictionary for the epoch\n",
    "\n",
    "        any_change_in_this_epoch = False\n",
    "\n",
    "        for train_step in tqdm(range(steps_per_epoch), desc=\"Training\"):\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            print(\"START NEW TRAINING STEP\")\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "\n",
    "            # try:\n",
    "            # load training data for the epoch\n",
    "            training_data = dataloader(train_df, bsz,\n",
    "                                       target_trainable_instruction, summarize_raw_instruction,\n",
    "                                       target_trainable_few_shot_examples, do_few_shot,\n",
    "                                       ngram_eval, factev,\n",
    "                                       dataloader_sample_mode)\n",
    "\n",
    "            #-----------\n",
    "            print(\"training metrics: before training step\")\n",
    "            eval_dict = eval_loop(training_data, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=True)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "            #-----------\n",
    "\n",
    "            print('training section:', training_data.index.tolist())\n",
    "\n",
    "            #train the \"instruction\"\n",
    "            if not do_few_shot:\n",
    "                target_trainable_instruction, is_updated = train_one_step(epoch, train_step, training_data, bsz,\n",
    "                                                                          target_trainable_instruction,\n",
    "                                                                          summarize_raw_instruction,\n",
    "                                                                          logging, learning_temperature_rate=learning_temperature_rate)\n",
    "\n",
    "            #train the few-shot-examples\n",
    "            if do_few_shot:\n",
    "                target_trainable_few_shot_examples = train_one_step_for_few_shot_example(epoch, train_step,\n",
    "                                                                                         training_data,\n",
    "                                                                                         bsz,\n",
    "                                                                                         target_trainable_instruction,\n",
    "                                                                                         target_trainable_few_shot_examples,\n",
    "                                                                                         summarize_raw_instruction,\n",
    "                                                                                         logging,\n",
    "                                                                                         learning_temperature_rate=0)\n",
    "                is_updated = True\n",
    "\n",
    "            if is_updated:\n",
    "                any_change_in_this_epoch = True\n",
    "\n",
    "            #-----------\n",
    "            print(\"training metrics: after training step\")\n",
    "            eval_dict = eval_loop(training_data, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=True)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "            #-----------\n",
    "            # except:\n",
    "            #     print('Encounter some errors from OpenAI API')\n",
    "            #     # print('Encounter some errors from OpenAI API, start to sleep 60s...')\n",
    "            #     # time.sleep(60)\n",
    "            #     # print('End sleep, resume the training')\n",
    "            #     continue\n",
    "\n",
    "\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "            print(\"END THIS TRAINING STEP\")\n",
    "            print(\"------------------------------------------------------------------\")\n",
    "\n",
    "        print(str(epoch), \"EPOCH END----------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH END----------------------------------------------------------------------------------------------------\")\n",
    "        print(str(epoch), \"EPOCH END----------------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        # do eval\n",
    "        if any_change_in_this_epoch:\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            print(\"eval results on all TRAINING DATA for EPOCH\", str(epoch))\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            eval_dict = eval_loop(train_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=False)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            print(\"eval results on all EVAL DATA for EPOCH\", str(epoch))\n",
    "            print(\"----------------------------------------------------------------------------------------------------------------\")\n",
    "            eval_dict = eval_loop(eval_df, target_trainable_instruction, summarize_raw_instruction,\n",
    "                                  target_trainable_few_shot_examples, do_few_shot,\n",
    "                                  ngram_eval, factev, eval_training_step=False)\n",
    "            eval_log(logging, epoch, eval_dict)\n",
    "\n",
    "            print(\"after curr epoch, the target_trainable_instruction is:\")\n",
    "            print(target_trainable_instruction)\n",
    "            if do_few_shot:\n",
    "                print(\"after curr epoch, the target_trainable_few_shot_examples is:\")\n",
    "                print(target_trainable_few_shot_examples)\n",
    "\n",
    "    return target_trainable_instruction, target_trainable_few_shot_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d943fc2-66f9-454b-be6c-c3cc2096a7b8",
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "93f1324fc1ba429dabefed4ab75e57b7",
      "45e7f42adbdf4a0a928757a18db6c40b",
      "0e5dbaf7bbb2407fb3f6da37cbc0758a",
      "065069ce2f8042b581f21aa25e3e1ab4",
      "50ec0444dc7b4b729eee547e4dafea54",
      "f7883d2296a643758f22833126226d0b",
      "9850b5fa36e84df3802c6426649bb2f1",
      "660d191266af479a8d466cc9b47ac29a",
      "fd901da4afd34e228d35ca52736bf862",
      "dca09d58397445909d6ed2a01adba33e",
      "84401351bcd14bcfab78073d83c35f57",
      "f25e7e20f03a4f43b9d6f0c05a8c7c3d",
      "3ee20976b53e49d582819f4deb4656ed",
      "f12b0f48393848f4af5838e2444c7625",
      "09c901c476ca4501955bf2eb637bc0d2",
      "b376a04b6e2544d1a61ffdc5b0744214",
      "8a15218021ff49e7a5d179453b283e2a",
      "ce5622464c714331aaf0967b28389733",
      "c398cc843bdb4713a875c29884b12533",
      "4ea6adeec760402b9a30073e6284fb09",
      "d9ee0a362c8b4db88227005b556c9ba3",
      "d3104aca1cc2413c9f5e1c1c445f0270",
      "240007fc6a87407a93b79c27dbefb6c3",
      "df4f3c9d01574f5fab0a3f7c59b6141f",
      "1e2f440e813146749270e34ad5d2262b",
      "df41d4847f2e4c0f94e107c6ae6a1a44",
      "459874aa369644e9ad9ad810f4f35efe",
      "6c94b148a3f642d69d9852c69a49a1b9",
      "6b92e90b16884736a519ed8c482febf9",
      "713e9e393c9d4845abff5a9f50db89cb",
      "7808c12421c8445aa6883b46aceea8b6",
      "268ffa6797dd422abea5bd6d0974e114",
      "dd209dbf181b4d0ab3fd9786739da31a",
      "ad021fa8333d4085bbf083ac08d7d060",
      "d1d6885cf3e14f45bfdc42ee47729e93",
      "37a07820e87047548265b15869adef17",
      "555303474e714a72a6c54230db1dee68",
      "d023885d754741c2900a62c0845c6813",
      "7b71024225fb4932bca5460e8c0b2971",
      "0ea1437a9e63418ba288de9459e3454f",
      "0d0500936c9e4c97bc9866659f08d0cc",
      "dc85fecf190b48979695dbaeb5e3b4c5",
      "19d11a7e02fd49cab5da61ad1569e12a",
      "d5a1e9d94efd4d3b88220705ff575613",
      "06420b8a37284106b736f2a51166725a",
      "63a2bcc4048c4ac9a46bb3f5a11e66cc",
      "6477a24a3c09492c8f93d3a203c6b5e8",
      "b72d79e88a2d4bdf9f9389e92f414f20",
      "cbc65849070b4bfb9c9267be0b3b811c",
      "e215b34aa16141f493b71cf82d680b13",
      "4a86c0bcc1184ea8bf070b275138bc3d",
      "e772cab346ae452ab2f7f8b4da9bbde5",
      "853fc4ade7fe4320bd93009e353eb74b",
      "bcb307df922b42d68e7d12960dae1262",
      "a386f5b0e4074c479d9d3bbd92d2d832",
      "dbb692d4e9fd4b93ab20cc25a374fc8e",
      "c6d7b6fab14e48a098d76f75d4d6048e",
      "a498dabe14134bdb81ae67badd289b53",
      "3d34c85886144b4e917a36b1d35ed065",
      "4b3b40e9cf7d44a5a34f0123a377a7d7",
      "7c8df1483ece469a815c9966b766cb04",
      "94715e265c154b2ebaf9dcff594be0b0",
      "b15b320e7efa48bebc8d230dcb7b93ab",
      "fcb2f59e48954783b5af007e4be045f0",
      "7728e929bcb94138abee93877406e4f2",
      "b73b1ad003da4a63ad2e3b08c3e95675",
      "ac88042d360c402ab4f92ce638c46380",
      "8ef25bd5dec84a0391e7648d4d2a436f",
      "302149ac753445e0a47482066ab8f1f0",
      "18b727b4996e41b28ee0521016ed2a00",
      "0c4bd6d0289542258b9020911d71b3ff",
      "73bae42178f04db2a7445e6c674accdd",
      "3a62d857723a437d91ad40e017f33970",
      "ad097376e8c7469195330374ec5a717c",
      "39e621972ebb4db883f32ef5f8be89be",
      "1f7f1036a697453d8d7511c35dfbf9b8",
      "05d09c08e45643a093ca33821f9a4dde",
      "a302adbf54d14999bfd7bc24cdd8b7ad",
      "e87a4b0bf5f841b3b8041d42b8160fef",
      "cda81fdc64334ce3bb7a5462a1a838dd",
      "562b9dc2d76f4fbe997e5d2bfd189949",
      "0619aafd97944edcae6e79ce4e7d48e9",
      "c6b0e635597943f08756b08b3bf7606b",
      "9816f6ee8a0f4e688ea0e564d754b3e8",
      "2c240e3d4d4c4c1a9ba2b675fa47d0bc",
      "f8471867a51440ce90f660685e30e5b5",
      "eafd5de57d93428b9615b8f0b596385f",
      "22f0db82c40e4e598dd00e96f1bc01e6",
      "78b33d857c484d13b9a59bd7fdf11d78",
      "8a9968bc949e48a185c84c7e1a8cf159",
      "bffbb90797864986a59b32a5274839a7",
      "006fc8adec134f67b2f9370c744616d9",
      "b4fdd0d0299c451699733f6eed003e25",
      "5dc0c3bcd0434eacaa22a7beee1c34b1",
      "c6d0d24beef24b10af84a0691146a841",
      "49363471e2f74f21867e321f6f8d9a40",
      "18d8c3bb43944dd5992ac9a3920a4cae",
      "d2945dc5b6c44942aaaafaac5169f5e7",
      "02119f13a0184dc98459a2ac836d99e1",
      "de7b61eaf2b045d9a766c2413ae98253",
      "49a03f1b99b647dbab6265a951873b30",
      "d0583a311e614a1abc0fe2a1b46a45e8",
      "8f1168320293493b9e2549c958f791ea",
      "19cd47a896904854abb0c1ce2260f865",
      "3ba2d9eef7a24967bfa99aa69f4d3340",
      "79872659aecc49f593b241ef763ac1da",
      "22168cadae0640db96741a4b48b78508",
      "6b3e6c88c81e4bed9046c17faf862357",
      "e5afc6ce71be4c27854403fba023cff9",
      "1e03e5b43efa4d97b148e34e2a6a896f",
      "f6b0e078b331440fa71c8c5cdf2248d3",
      "7187cdbf6ce5490f83189c67fc57d613",
      "2d5aca0927b64d68a9711ac695c27bd8",
      "5dc713f722ef42db8273fd54ad8fff7f",
      "7e22f94a3188438fbadae3bea17663d0",
      "3f98bcb906ee41e7ae361f42ed0a26db",
      "6ddc8b966c4c408a80a5c970b8915cc4",
      "d4182cbeffe14030a3af2fcf4678874f",
      "a0535ae6a71440b1b59942c8aca198a2",
      "aa534ee5511e4e9a8cb0f6cc0fc9e1dd",
      "b31b44e693ed4c37a47d71c6a393acad",
      "48927e1ad3494b1e943edbe5b1018c39",
      "759f0c70e0b041b6807d222886fb3596",
      "88de90ad338f4f369b89e9ba874662c2",
      "fed7b3b53a944ea985941927ac5a2be2",
      "151ffe232e54487dbb3b2e466b7e5c6a",
      "e5a91a848b3646ddb7ac716ad5504e23",
      "698a6b73c7f94d17ad9e70d837114271",
      "6acae511c9c848a58b631da9dcede57f",
      "73c2b26ad9db46d3b16159820c9751c0",
      "eb60f3654d4247638fbe9196deb57ea5",
      "501ce46b484644afad4cc3a78275e3d9",
      "3c9ab6b24c744335b102244fdac36481",
      "36d1a50271cd41e09f68032eb50c1fad",
      "2124d3600f93425e80b5421a6b794673",
      "d5fd9de663954c3bb0f55aa2f5d99d7d",
      "a38e7798bfc44cb699c6d94248a76b38",
      "58b48d47e7ac4f9bbcbafbbac837de82",
      "e1e61564f8534c98bf864124596e7cdb",
      "8413b2781f9d4aee89f9fa1f4977605e",
      "25623a6645444b7982dbfd9d4219d916",
      "57d3ac099ebf4c8a8d9e434a6df0220f",
      "6bb829ea7c7c4e6684d32b0caf67fa80",
      "98a23a5a451142f68451fe78afa43d07",
      "bef76cd0babe404dbba900ad35fc14f2",
      "b8646866ce224256a13aa6ceb8532efe",
      "7f8b3aa62e3345209b439600882c77cd",
      "f8985e1f6aeb4c6eabe9238388b3c5fd",
      "3b85b3c6db144585994acbb16e77ab62",
      "f4e737186cb14efca0c3454475cc5305",
      "cf19f2883cb14cd0895b632f140cb1b3",
      "f1c77e1fe9a94175b3591ea08db820ad",
      "7afcc96257c84a0b92e814839d7c043d",
      "569c61e13f85483297253384ea21eca1",
      "33f4ab6ecfcf4159861c2ee6580d503b",
      "843c4cf86e574f318d76f53f95103e0b",
      "058547c8ff254c0d89479e152e81ed68",
      "633296583371430cb854c894cec558a8",
      "f8097b624f6d433c8d5894754d297513",
      "04af519972624581a4721e095415aefc",
      "41023941b8934bcb9e6e992d39689b38",
      "832cb891683c4fcc85152917bff5fd75",
      "d31dc9fbd008458aaf054680c0517c74",
      "c283b121e6c2408e9cc12a4b9185afef",
      "922d717f23244d0083a435da2538d14d",
      "e558de68bef241b3ab7f5ef9cf6f3987",
      "b117c92e1a5d4e51869fc835af24ba5a",
      "b7e63387c93a4c9fba01f3970dc057be",
      "db9848fc79ee470793b560dc982f86bc",
      "251191c7b9c8430498749681b2aa5dd1",
      "1f0a146ffd04470d966f1df0f72cef3b",
      "3a797a1e149344c8a82629b3617810e0",
      "20904aa82f9d41f39c954eb8381cfd8d"
     ]
    },
    "id": "1d943fc2-66f9-454b-be6c-c3cc2096a7b8",
    "outputId": "eb95b2e5-94ef-4787-ad6a-2ed1001d4030"
   },
   "outputs": [],
   "source": [
    "ngram_eval = AutomaticNgramEval()\n",
    "# factev = AutomaticFactEval() \n",
    "factev=None \n",
    "\n",
    "target_trainable_instruction, target_trainable_few_shot_examples = train_loop(train_df, eval_df,\n",
    "                                                                              target_trainable_instruction,\n",
    "                                                                              summarize_raw_instruction, logging,\n",
    "                                                                              ngram_eval, factev,\n",
    "                                                                              target_trainable_few_shot_examples='',\n",
    "                                                                              do_few_shot=False,\n",
    "                                                                              EPOCH=1, steps_per_epoch=5, bsz=5,\n",
    "                                                                              eval_at_beginning=True,\n",
    "                                                                              dataloader_sample_mode='random',\n",
    "                                                                              learning_temperature_rate=0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
